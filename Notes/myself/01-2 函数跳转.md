好的，以下是基于 **Linux 5.10** 版本的内存管理框架、虚拟内存管理、物理内存管理、页表映射、以及内存申请与回收的详细源码分析，以及函数的跳转关系。

### **第一章：内存管理框架**

#### 1.1 内存管理的整体架构

在 Linux 5.10 内核中，内存管理框架依赖于进程的 `mm_struct` 和区域 `vm_area_struct` 来管理内存的分配和使用。

- **mm_struct**：进程的内存管理信息（包括页表、内存区域等）。
- **vm_area_struct**：描述虚拟内存区域。

**源码位置：**

- `include/linux/mm_types.h`：定义了 `mm_struct` 和 `vm_area_struct`。
- `mm/mmap.c`：处理内存映射和区域管理。

**关键函数分析：**

- ```
  do_mmap()
  ```

  : 负责进程内存映射，创建新的 

  ```
  vm_area_struct
  ```

  - 函数跳转关系：

    - `do_mmap()` 调用 `get_unmapped_area()` 确定合适的虚拟地址，然后通过 `mmap_region()` 创建虚拟内存区域。
  - `mmap_region()` 会调用 `vma_adjust()` 调整虚拟内存区域。

**代码路径：**

- `mm/mmap.c`: `do_mmap()`, `mmap_region()`

------

### **第二章：虚拟内存管理**

#### 2.1 虚拟内存分配与管理

虚拟内存通过页表管理，虚拟地址到物理地址的映射需要通过分页机制完成。

**源码位置：**

- `mm/mmap.c`：处理用户空间的虚拟内存分配。
- `arch/x86/mm/init_64.c`：初始化虚拟内存结构，基于 64 位架构。
- `mm/memory.c`：虚拟内存页面的处理。

**关键函数分析：**

- `handle_mm_fault()`：处理页面缺失错误。

  - 函数跳转关系：

    - `handle_mm_fault()` 调用 `do_page_fault()` 来处理缺页中断，最终调用 `alloc_pages_vma()` 分配内存页。

- `do_page_fault()`：处理进程中的缺页错误。

  - 函数跳转关系：

    - 当进程访问无效内存时，`do_page_fault()` 调用 `handle_mm_fault()` 进行页面分配。

**代码路径：**

- `mm/memory.c`: `handle_mm_fault()`, `do_page_fault()`

------

### **第三章：物理内存管理**

#### 3.1 物理内存的分配与管理

物理内存由伙伴系统（Buddy System）管理。伙伴系统使用页块来管理不同大小的物理内存段。

**源码位置：**

- `mm/page_alloc.c`：实现了物理内存的分配和管理。
- `include/linux/mmzone.h`：描述物理内存的分区、区块和页的结构。

**关键函数分析：**

- `__alloc_pages()`：分配物理页。

  - 函数跳转关系：

    - `__alloc_pages()` 调用 `rmqueue()` 从伙伴系统中获取内存页。
  - `rmqueue()` 负责从对应的内存区分配页，调用 `__free_one_page()` 进行内存页的释放。
  
- `free_pages()`：释放物理页。

  - 函数跳转关系：

    - `free_pages()` 调用 `__free_pages_ok()` 将物理页释放回伙伴系统。

**代码路径：**

- `mm/page_alloc.c`: `__alloc_pages()`, `free_pages()`, `__free_pages_ok()`

------

### **第四章：页表映射**

#### 4.1 页表映射和虚拟地址映射

Linux 5.10 版本中的页表结构使用多级页表，通常是 4 级或 5 级页表，页表管理虚拟内存与物理内存的映射关系。

**源码位置：**

- `arch/x86/include/asm/pgtable.h`：定义了页表的宏和页表结构。
- `arch/x86/mm/pgtable.c`：实现页表相关操作。

**关键函数分析：**

- `pgd_alloc()`：分配页全局目录 (PGD)。

  - 函数跳转关系：

    - `pgd_alloc()` 调用 `pud_alloc()`，然后依次分配 PUD（页上级目录）、PMD（页中间目录）、PTE（页表项）。

- `pte_alloc()`：分配页表。

  - 函数跳转关系：

    - `pte_alloc()` 调用 `pte_alloc_one()` 分配具体的页表。

- `set_pte()`：设置页表项，将虚拟地址映射到物理地址。

  - 函数跳转关系：

    - `set_pte()` 用于更新页表项，最后的物理地址与虚拟地址的映射在此实现。

**代码路径：**

- `arch/x86/mm/pgtable.c`: `pgd_alloc()`, `pud_alloc()`, `pte_alloc()`, `set_pte()`

------

### **第五章：内存申请与回收**

#### 5.1 内存申请：伙伴系统与 slab/slub 分配器

伙伴系统用于大块内存分配，slab/slub 分配器用于小块内存的高效分配。

**源码位置：**

- `mm/page_alloc.c`：伙伴系统。
- `mm/slab.c` 和 `mm/slub.c`：slab/slub 分配器。

**关键函数分析：**

- `__alloc_pages()`：物理页的分配。

  - 函数跳转关系：

    - 调用 `rmqueue()` 从伙伴系统获取内存。

- `kmem_cache_alloc()`：slab 分配器分配小块内存。

  - 函数跳转关系：

    - `kmem_cache_alloc()` 调用 `slab_alloc()` 执行具体的内存分配。

- `kmem_cache_free()`：释放 slab 中的小块内存。

  - 函数跳转关系：

    - `kmem_cache_free()` 调用 `slab_free()` 进行内存的回收。

#### 5.2 内存回收：OOM Killer 和 Swap

当内存耗尽时，Linux 内核会调用 OOM Killer 终止进程释放内存，或通过 Swap 机制将内存页交换到磁盘。

**源码位置：**

- `mm/oom_kill.c`：实现 OOM Killer。
- `mm/vmscan.c`：页面回收与 Swap 的实现。

**关键函数分析：**

- `oom_kill_process()`：选择需要终止的进程。

  - 函数跳转关系：

    - 调用 `select_bad_process()` 选择最适合的进程进行杀死，以释放内存。

- `try_to_free_pages()`：尝试回收内存页。

  - 函数跳转关系：

    - 当内存紧缺时，`try_to_free_pages()` 调用 `shrink_zones()` 来回收内存。
- `shrink_zones()` 会通过 `shrink_inactive_list()` 扫描不活跃的页面并将其回收到内存池或写入 Swap 设备。

**代码路径：**

- `mm/oom_kill.c`: `oom_kill_process()`
- `mm/vmscan.c`: `try_to_free_pages()`, `shrink_zones()`

------

这份基于 **Linux 5.10** 版本的详细源码分析，涵盖了你需要的每个章节中的关键函数及其跳转关系和代码位置。通过这些分析，你可以在 PPT 中结合实际源码展示，深入讲解每个内存管理机制的实现细节。





# 第一章

在 Linux 5.10 内核中，内存管理框架依赖于 `mm_struct` 和 `vm_area_struct` 来管理内存的分配和使用。这两个结构体用于管理进程的内存信息以及进程地址空间中的各个内存区域。`mm_struct` 保存了进程的全局内存管理信息，而 `vm_area_struct` 负责具体描述某个虚拟内存区域。

接下来，我们重点分析 `do_mmap()` 以及相关函数 `mmap_region()` 和 `vma_adjust()`，深入理解它们在内存映射中的角色与源码实现。

### **1.1.1 `mm_struct` 和 `vm_area_struct`**

#### `mm_struct` 结构体

`mm_struct` 结构体是内存管理的核心，代表了每个进程的整个内存状态，它记录了页表、内存区域、虚拟内存映射、共享内存等信息。

**源码位置：`include/linux/mm_types.h`**

```
struct mm_struct {
    struct vm_area_struct *mmap;  /* List of VMAs */
    struct rb_root mm_rb;
    unsigned long (*get_unmapped_area) (struct file *, unsigned long, unsigned long, unsigned long, unsigned long);
    ...
    struct pgd_t *pgd;  /* 页表的基地址 */
    ...
};
```

- `mmap`：指向该进程的虚拟内存区域链表的起始位置。每个虚拟内存区域通过 `vm_area_struct` 进行描述。
- `pgd`：指向进程的页全局目录 (Page Global Directory) 的指针，即页表的基地址。
- `get_unmapped_area`：用于查找一个未映射的虚拟地址区段，主要由 `do_mmap()` 调用。

#### `vm_area_struct` 结构体

`vm_area_struct` 结构体用来描述虚拟内存区域（VMA），这些区域是一个连续的虚拟地址空间。

**源码位置：`include/linux/mm_types.h`**

```
struct vm_area_struct {
    unsigned long vm_start;    /* 虚拟内存区域的起始地址 */
    unsigned long vm_end;      /* 虚拟内存区域的结束地址 */
    struct mm_struct *vm_mm;   /* 所属的进程内存描述符 */
    struct vm_area_struct *vm_next;  /* 下一块虚拟内存区域 */
    pgprot_t vm_page_prot;     /* 页保护 */
    unsigned long vm_flags;    /* 区域的标志（可读、可写等） */
    ...
};
```

- `vm_start` 和 `vm_end`：定义了虚拟内存区域的起始和结束地址。
- `vm_next`：指向下一个虚拟内存区域。
- `vm_flags`：保存该内存区域的属性，如可读、可写、可执行等。

### **1.1.2 `do_mmap()` 函数分析**

`do_mmap()` 是虚拟内存映射的核心函数，用于将文件或设备的内容映射到虚拟内存空间中。它会创建一个新的 `vm_area_struct` 实例来描述该映射区域，并将其插入到进程的虚拟内存区域链表中。

**源码位置：`mm/mmap.c`**

```
unsigned long do_mmap(struct file *file, unsigned long addr, unsigned long len,
                      unsigned long prot, unsigned long flags,
                      unsigned long pgoff, unsigned long *populate, struct list_head *uf)
{
    struct mm_struct *mm = current->mm;
    unsigned long retval;
    
    /* Step 1: 调用 get_unmapped_area 查找可用的虚拟地址区段 */
    if (!addr) {
        addr = mm->get_unmapped_area(file, addr, len, pgoff, flags);
        if (IS_ERR_VALUE(addr))
            return addr;
    }

    /* Step 2: 检查区域是否已经被映射 */
    retval = security_mmap_addr(addr);
    if (retval)
        return retval;

    /* Step 3: 创建新的虚拟内存区域 */
    retval = mmap_region(file, addr, len, prot, flags, pgoff, uf);
    if (!IS_ERR_VALUE(retval))
        *populate = addr;
    
    return retval;
}
```

#### 过程分析：

1. **查找可用的虚拟地址区段**：
   - `do_mmap()` 首先调用 `get_unmapped_area()` 函数，该函数通过扫描进程的地址空间，寻找一个长度为 `len` 的未使用虚拟地址区段。该函数返回的地址将用于映射。
   - `get_unmapped_area()` 是 `mm_struct` 中的一个函数指针，根据文件系统类型可能会有不同的实现（例如普通文件、匿名映射等）。
2. **安全性检查**：
   - `do_mmap()` 调用 `security_mmap_addr()` 进行地址安全性检查，确保地址合法。如果不合法，则返回错误代码。
3. **创建新的虚拟内存区域**：
   - 调用 `mmap_region()` 来创建并插入新的 `vm_area_struct`，表示新的内存映射区域。

### **1.1.3 `mmap_region()` 函数分析**

`mmap_region()` 函数用于在指定的地址区段上创建一个新的 `vm_area_struct`，并将其插入到进程的内存区域链表中。

**源码位置：`mm/mmap.c`**

```
static unsigned long mmap_region(struct file *file, unsigned long addr,
                                 unsigned long len, unsigned long prot,
                                 unsigned long flags, unsigned long pgoff,
                                 struct list_head *uf)
{
    struct mm_struct *mm = current->mm;
    struct vm_area_struct *vma, *prev;
    int error;

    /* Step 1: 分配一个新的 vm_area_struct */
    vma = vm_area_alloc(mm);
    if (!vma)
        return -ENOMEM;

    vma->vm_start = addr;
    vma->vm_end = addr + len;
    vma->vm_flags = calc_vm_prot_bits(prot, flags);
    vma->vm_file = file;

    /* Step 2: 调整并插入新的 vm_area_struct */
    prev = find_vma_prev(mm, addr);
    vma_adjust(prev, addr, addr + len, len);

    /* Step 3: 将虚拟内存区域插入进程的 VMA 链表中 */
    vma_link(mm, vma, prev);
    
    return addr;
}
```

#### 过程分析：

1. **分配新的 `vm_area_struct`**：
   - `vm_area_alloc()` 函数为该内存映射区域分配内存，并初始化 `vm_area_struct`。
   - `vm_start` 和 `vm_end` 分别表示该虚拟内存区域的起始和结束地址。
   - `vm_flags` 用来存储内存区域的权限位，如可读、可写、可执行等。
2. **调整虚拟内存区域**：
   - 调用 `vma_adjust()` 对虚拟内存区域进行调整，确保地址不冲突。
   - `vma_adjust()` 负责调整邻接的虚拟内存区域，以确保内存的连续性。
3. **将 VMA 插入到进程的 VMA 链表中**：
   - 通过 `vma_link()` 函数将新创建的 `vm_area_struct` 插入到进程的虚拟内存区域链表中，`prev` 表示当前的上一个 VMA。

### **1.1.4 `vma_adjust()` 函数分析**

`vma_adjust()` 函数用于调整新的虚拟内存区域，并确保与相邻的内存区域没有重叠或冲突。

**源码位置：`mm/mmap.c`**

```
c复制代码static void vma_adjust(struct vm_area_struct *vma, unsigned long start,
                       unsigned long end, unsigned long pgoff)
{
    ...
    /* 调整 VMA 的起始和结束地址 */
    vma->vm_start = start;
    vma->vm_end = end;

    /* 更新内存区域的偏移 */
    vma->vm_pgoff = pgoff;

    ...
}
```

#### 过程分析：

- `vma_adjust()` 将新的 `vm_area_struct` 的起始地址 `start` 和结束地址 `end` 进行调整，确保区域正确。
- 如果需要，也会修改 VMA 的页面偏移 `pgoff`。

### **总结**

- `do_mmap()` 是内存映射的核心函数，它负责创建并初始化新的 `vm_area_struct`，该结构体管理虚拟内存区域的分配和属性。
- `do_mmap()` 通过调用 `get_unmapped_area()` 查找可用的虚拟地址区段，随后调用 `mmap_region()` 创建并插入新的虚拟内存区域。
- `mmap_region()` 函数通过 `vma_adjust()` 和 `vma_link()` 完成区域的调整和插入操作，确保虚拟内存区域的连续性和正确性。

这个流程涵盖了虚拟内存区域的查找、分配、调整与插入操作，结合实际的源码路径，可以为你在讲解内存管理框架时提供详细的技术支持。

# 第二章

在 Linux 内核中，虚拟内存管理是通过页表来管理的，它负责将虚拟地址映射到物理地址，并且通过分页机制确保内存的高效使用。当进程访问尚未映射的虚拟地址时，内核会通过页错误（page fault）来捕捉这一事件，并通过缺页处理机制为该地址分配物理内存。下面我们将深入分析虚拟内存管理中几个关键的源码实现，包括 `handle_mm_fault()` 和 `do_page_fault()`。

### **2.1.1 虚拟内存分配与页面处理：`handle_mm_fault()`**

`handle_mm_fault()` 是处理缺页错误的关键函数。当进程访问尚未映射的虚拟地址时，内核会触发缺页中断，调用 `do_page_fault()`，进而通过 `handle_mm_fault()` 来分配相应的物理页，并更新页表。

#### **`handle_mm_fault()` 源码分析**

**源码位置：`mm/memory.c`**

```
int handle_mm_fault(struct vm_area_struct *vma, unsigned long address, unsigned int flags)
{
    struct mm_struct *mm = vma->vm_mm;
    pgd_t *pgd;
    p4d_t *p4d;
    pud_t *pud;
    pmd_t *pmd;
    pte_t *pte;

    /* Step 1: 获取进程的页全局目录 */
    pgd = pgd_offset(mm, address);
    p4d = p4d_offset(pgd, address);
    pud = pud_offset(p4d, address);
    pmd = pmd_offset(pud, address);
    pte = pte_offset_map(pmd, address);

    /* Step 2: 检查页面是否已经存在 */
    if (!pte_present(*pte)) {
        /* Step 3: 分配新的物理页 */
        return alloc_pages_vma(vma, address, flags);
    }

    /* Step 4: 如果页面已经存在但不可写，则处理写时复制 (COW) */
    if (flags & FAULT_FLAG_WRITE && !pte_write(*pte))
        return do_wp_page(vma, address, pte);
    
    return 0;
}
```

#### **函数过程分析：**

1. **Step 1: 获取页表层级结构**：
   - `pgd_offset()`：根据虚拟地址获取页全局目录（PGD）项。
   - `p4d_offset()`：从 PGD 获取到页上级目录（P4D）。
   - `pud_offset()`：从 P4D 获取页上中间目录（PUD）。
   - `pmd_offset()`：从 PUD 获取页中间目录（PMD）。
   - `pte_offset_map()`：从 PMD 获取页表项（PTE），这是虚拟地址到物理页的最后一级映射。
2. **Step 2: 检查页面是否已经存在**：
   - `pte_present()` 用于检查页表项是否已经映射到物理地址。如果返回值为 `false`，意味着此虚拟地址尚未映射到物理内存。
3. **Step 3: 分配新的物理页**：
   - 如果页面不存在，调用 `alloc_pages_vma()` 为该地址分配物理页，并将其映射到虚拟地址上。
4. **Step 4: 写时复制 (COW)**：
   - 如果进程尝试写入只读页面，内核会调用 `do_wp_page()` 处理写时复制，确保写操作不会影响到共享页面。

#### **`alloc_pages_vma()` 函数分析**

`alloc_pages_vma()` 负责为缺失的页面分配物理页，通常由 `handle_mm_fault()` 在缺页处理时调用。

**源码位置：`mm/memory.c`**

```
int alloc_pages_vma(struct vm_area_struct *vma, unsigned long addr, unsigned int flags)
{
    struct page *page;
    struct mm_struct *mm = vma->vm_mm;
    
    /* Step 1: 调用伙伴系统分配页面 */
    page = alloc_pages(gfp_mask, 0);
    if (!page)
        return -ENOMEM;

    /* Step 2: 将物理页映射到虚拟地址 */
    set_pte_at(mm, addr, pte, mk_pte(page, vma->vm_page_prot));

    return 0;
}
```

#### **函数过程分析：**

1. **Step 1: 调用 `alloc_pages()` 分配物理页**：
   - `alloc_pages()` 函数负责从伙伴系统（Buddy System）中分配一个物理页面。该函数会根据需要的页框大小和分配标志分配页面。
2. **Step 2: 将物理页映射到虚拟地址**：
   - `set_pte_at()` 用于将分配的物理页映射到指定的虚拟地址。`mk_pte()` 将物理页和页保护信息（如读写权限）封装为一个页表项。

------

### **2.1.2 缺页中断处理：`do_page_fault()`**

当进程访问的虚拟地址无效或尚未映射时，会触发缺页中断（page fault）。`do_page_fault()` 是缺页中断处理的入口函数，它会检查缺页原因，并决定如何处理。

#### **`do_page_fault()` 源码分析**

**源码位置：`arch/x86/mm/fault.c`**

```
asmlinkage void do_page_fault(struct pt_regs *regs, unsigned long error_code)
{
    struct mm_struct *mm;
    struct task_struct *tsk;
    struct vm_area_struct *vma;
    unsigned long address;
    int fault;

    /* Step 1: 获取出错地址 */
    address = read_cr2();

    tsk = current;
    mm = tsk->mm;

    /* Step 2: 查找虚拟内存区域 */
    vma = find_vma(mm, address);
    if (!vma || vma->vm_start > address)
        goto no_context;

    /* Step 3: 调用 handle_mm_fault() 处理缺页 */
    fault = handle_mm_fault(vma, address, flags);
    if (fault & VM_FAULT_OOM)
        goto out_of_memory;
}
```

#### **函数过程分析：**

1. **Step 1: 获取缺页的虚拟地址**：
   - 缺页发生时，CPU 会将出错的虚拟地址保存在寄存器 `CR2` 中，`read_cr2()` 读取该寄存器，获取出错的虚拟地址。
2. **Step 2: 查找虚拟内存区域**：
   - 使用 `find_vma()` 函数在进程的虚拟内存区域链表中查找包含该地址的 `vm_area_struct`。如果找不到对应的虚拟内存区域，意味着进程尝试访问的是非法地址，此时会跳转到 `no_context` 处理异常。
3. **Step 3: 调用 `handle_mm_fault()` 处理缺页**：
   - 如果找到了对应的虚拟内存区域，`do_page_fault()` 会调用 `handle_mm_fault()` 来处理具体的缺页问题。这时，内核将尝试分配新的物理页，并将其映射到缺页的虚拟地址上。

#### **异常处理：**

- **Out of Memory (OOM)**：
  - 如果 `handle_mm_fault()` 处理时内存不足（`VM_FAULT_OOM`），则跳转到 `out_of_memory` 标签，触发 OOM Killer 以释放内存。
- **非法访问：**
  - 如果 `find_vma()` 找不到包含该地址的虚拟内存区域，则跳转到 `no_context`，处理非法访问异常。

------

### **2.1.3 页表结构及映射过程**

Linux 采用多级页表结构（通常是四级：PGD、P4D、PUD、PMD 和 PTE），用于将虚拟地址映射到物理地址。每一级页表都有不同的功能，逐层缩小地址空间，最终映射到实际的物理页。

#### **页表层级结构的例子：**

- **PGD (Page Global Directory)**：页全局目录，虚拟地址最高位。
- **P4D (Page Upper Directory)**：上级页目录。
- **PUD (Page Upper Directory)**：上中间页目录。
- **PMD (Page Middle Directory)**：中间页目录。
- **PTE (Page Table Entry)**：页表项，指向具体的物理页。

在 `handle_mm_fault()` 中，可以看到每一级页表是通过各自的偏移函数（例如 `pgd_offset()`、`p4d_offset()`）来获取的。这种分层结构允许大规模地址空间的管理，并有效降低内存管理的开销。

------

### **总结**

虚拟内存管理在 Linux 内核中通过分层的页表结构和缺页中断机制来管理。`handle_mm_fault()` 是核心的缺页处理函数，通过分配物理页并更新页表来完成虚拟地址到物



# 第三章

在 Linux 5.10 内核中，物理内存的分配与管理主要依赖于伙伴系统（Buddy System）。该系统通过将内存页划分为不同大小的块来实现内存的分配和回收。我们将在此详细分析物理内存的分配、释放过程，并解读相关源码函数的工作原理及跳转关系。

### **3.1.1 物理内存的分配：`__alloc_pages()`**

`__alloc_pages()` 是物理内存页分配的核心函数，负责通过伙伴系统分配物理页。伙伴系统将物理内存分为大小不一的块（页块），并以 2 的倍数递增管理这些块。当内核需要分配特定数量的页时，它会尝试找到最合适的页块大小，以避免内存碎片。

#### **`__alloc_pages()` 函数源码分析**

**源码位置：`mm/page_alloc.c`**

```
c复制代码struct page * __alloc_pages(gfp_t gfp_mask, unsigned int order, struct zonelist *zonelist)
{
    struct page *page;
    struct alloc_context ac = { };

    /* Step 1: 初始化内存分配上下文 */
    if (unlikely(gfp_mask & __GFP_HIGHMEM))
        ac.migratetype = MIGRATE_HIGHMEM;
    else
        ac.migratetype = MIGRATE_UNMOVABLE;

    /* Step 2: 进行内存分区的搜索和分配 */
    page = get_page_from_freelist(gfp_mask, order, zonelist, ac);
    if (!page)
        page = __alloc_pages_slowpath(gfp_mask, order, zonelist, ac);

    return page;
}
```

#### **函数过程分析：**

1. **Step 1: 初始化内存分配上下文**：
   - 根据 `gfp_mask` 标志位，确定要分配的内存类型（例如高内存、高速缓存、不可移动内存等）。
   - 这里使用的 `migratetype` 表示页面的迁移类型，内核将页面分类为可移动、不可移动或可回收的，以方便内存管理。
2. **Step 2: 搜索内存分区并进行分配**：
   - `get_page_from_freelist()`：这是内存分配的核心函数，负责从伙伴系统中找到符合要求的空闲页面。它遍历不同的内存区并尝试找到合适的空闲页。

#### **`get_page_from_freelist()` 函数分析**

**源码位置：`mm/page_alloc.c`**

```
c复制代码struct page *get_page_from_freelist(gfp_t gfp_mask, unsigned int order,
                                    struct zonelist *zonelist, struct alloc_context *ac)
{
    struct zone *zone;
    struct page *page;

    /* Step 1: 遍历可用内存区 (zone)，查找适合的页面 */
    for_each_zone_zonelist_nodemask(zone, z, zonelist, ac->highest_zoneidx, ac->nodemask) {
        page = rmqueue(zone, order, ac->migratetype);
        if (page)
            return page;
    }
    
    return NULL;
}
```

#### **函数过程分析：**

1. **遍历可用的内存区**：
   - `for_each_zone_zonelist_nodemask()` 宏负责遍历给定的 `zonelist`，这是内存区列表，包含了可分配内存的不同区域（例如 DMA 区、高速缓存区等）。遍历时会考虑 `gfp_mask` 和内存类型。
2. **调用 `rmqueue()` 分配页面**：
   - `rmqueue()` 是负责从伙伴系统中获取页面的核心函数，它将尝试从给定的内存区中分配指定数量的页（根据 `order` 决定分配几页，`order = 0` 表示分配 1 页）。

#### **`rmqueue()` 函数分析**

**源码位置：`mm/page_alloc.c`**

```
c复制代码struct page *rmqueue(struct zone *zone, unsigned int order, int migratetype)
{
    struct page *page;
    
    /* Step 1: 从伙伴系统的 free_list 中找到合适的空闲页 */
    page = __rmqueue(zone, order, migratetype);

    /* Step 2: 清空该页面的内容，并返回页的指针 */
    prep_new_page(page, order, gfp_flags);

    return page;
}
```

#### **函数过程分析：**

1. **Step 1: 从伙伴系统获取空闲页**：
   - `__rmqueue()`：负责从伙伴系统的 free_list（空闲链表）中获取指定大小（`order` 决定）的页块。它会尝试找到合适的页块，并将该页块从空闲链表中移除。
2. **Step 2: 准备分配的页面**：
   - `prep_new_page()`：为分配的新页面做好初始化工作（如清除页面内容、设置页面标志等），然后返回页面指针。

通过上述步骤，`__alloc_pages()` 完成了物理内存页的分配。如果 `get_page_from_freelist()` 无法找到空闲页，内核会进入 `__alloc_pages_slowpath()`，尝试通过其他方式（如页面回收）来获得内存。

------

### **3.1.2 物理内存的释放：`free_pages()`**

内存页的释放通过 `free_pages()` 函数完成，它调用 `__free_pages_ok()` 函数将内存页归还给伙伴系统，以便其他进程或内核模块继续使用。

#### **`free_pages()` 函数分析**

**源码位置：`mm/page_alloc.c`**

```
c复制代码void free_pages(unsigned long addr, unsigned int order)
{
    if (addr != 0) {
        struct page *page = virt_to_page(addr);
        __free_pages(page, order);
    }
}
```

#### **函数过程分析：**

1. 地址转换

   ：

   - `virt_to_page()` 函数将虚拟地址转换为物理页的 `struct page` 结构体。
   - 接着调用 `__free_pages()`，根据页块的大小（由 `order` 决定），将页面归还给伙伴系统。

#### **`__free_pages()` 和 `__free_pages_ok()` 函数分析**

**源码位置：`mm/page_alloc.c`**

```
c复制代码void __free_pages(struct page *page, unsigned int order)
{
    if (page) {
        __free_pages_ok(page, order);
    }
}

static void __free_pages_ok(struct page *page, unsigned int order)
{
    unsigned long pfn = page_to_pfn(page);
    struct zone *zone = page_zone(page);
    
    /* Step 1: 将页面归还给伙伴系统 */
    __free_one_page(zone, page, pfn, order, 0);
}
```

#### **函数过程分析：**

1. 页面的释放

   ：

   - `__free_pages_ok()` 调用 `__free_one_page()` 函数，将指定的页面归还到伙伴系统中。`page_to_pfn()` 用于获取页框号（PFN），`page_zone()` 返回页面所在的内存区。

#### **`__free_one_page()` 函数分析**

**源码位置：`mm/page_alloc.c`**

```
c复制代码static void __free_one_page(struct zone *zone, struct page *page,
                            unsigned long pfn, unsigned int order, int migratetype)
{
    /* Step 1: 将该页块重新插入伙伴系统的空闲链表 */
    list_add(&page->lru, &zone->free_area[order].free_list[migratetype]);

    /* Step 2: 更新伙伴系统的信息 */
    zone->free_area[order].nr_free++;
}
```

#### **函数过程分析：**

1. 归还页面

   ：

   - `list_add()`：将页面重新加入到 `free_list`（伙伴系统的空闲链表）中。

2. 更新伙伴系统状态

   ：

   - `nr_free++`：更新伙伴系统的统计信息，增加空闲页块的数量。

------

### **总结**

通过详细分析 Linux 5.10 内核中的物理内存分配与释放过程，我们了解到：

- **物理内存的分配**：通过 `__alloc_pages()` 函数分配物理页，调用 `get_page_from_freelist()` 从伙伴系统中查找并分配合适的页块。如果失败，内核会进入慢路径进一步尝试分配。
- **物理内存的释放**：`free_pages()` 调用 `__free_pages_ok()` 将物理页归还伙伴系统，`__free_one_page()` 将页块重新插入空闲链表并更新伙伴系统状态。

这些函数通过紧密的跳转关系，确保物理内存的高效管理，避免碎片化，并在不同场景下灵活进行分配和回收操作。



# 第四章

在 Linux 5.10 版本的内核中，虚拟地址到物理地址的映射是通过多级页表结构实现的。典型的 x86-64 架构使用四级页表（有时是五级），包括：页全局目录 (PGD)、页上级目录 (P4D)、页上中间目录 (PUD)、页中间目录 (PMD) 和页表项 (PTE)。每一级页表逐步缩小虚拟地址空间，最终指向实际的物理内存地址。

下面详细分析页表的分配、映射和操作的核心函数，并讲解它们的执行过程及源码实现。

### **4.1.1 页表结构简介**

页表是一个层次结构，最高层的页表指向下一层，直到最后一层（PTE），其中存储了虚拟地址到物理地址的实际映射关系。页表的层次结构如下：

- **PGD (Page Global Directory)**：页全局目录，指向下一层页上级目录。
- **P4D (Page Upper Directory)**：页上级目录，指向页上中间目录。
- **PUD (Page Upper Directory)**：页上中间目录，指向页中间目录。
- **PMD (Page Middle Directory)**：页中间目录，指向页表项。
- **PTE (Page Table Entry)**：页表项，最终指向实际的物理页。

------

### **4.1.2 页表分配与映射：`pgd_alloc()`**

`pgd_alloc()` 是分配页全局目录 (PGD) 的函数，它是处理页表映射的第一步。该函数在进程创建时调用，用来为进程初始化页表结构。

#### **`pgd_alloc()` 源码分析**

**源码位置：`arch/x86/mm/pgtable.c`**

```
c复制代码pgd_t *pgd_alloc(struct mm_struct *mm)
{
    pgd_t *pgd;

    /* Step 1: 从伙伴系统分配一个页全局目录 */
    pgd = (pgd_t *)get_zeroed_page(GFP_KERNEL);
    if (!pgd)
        return NULL;

    /* Step 2: 初始化页全局目录 */
    pgd_init(pgd);

    return pgd;
}
```

#### **函数过程分析：**

1. Step 1: 分配页全局目录 (PGD)

   ：

   - `get_zeroed_page(GFP_KERNEL)` 调用伙伴系统分配一个物理页面，并将其内容清零。该页面用于存储 PGD（页全局目录）。

2. Step 2: 初始化页全局目录

   ：

   - `pgd_init()` 函数初始化分配的页全局目录，设置起始的页表项。

接下来，系统会根据需要依次分配页表的下层结构，如 PUD、PMD 和 PTE。为了实现这种层级结构的分配，`pgd_alloc()` 调用 `pud_alloc()`、`pmd_alloc()` 等函数进行逐层分配。

#### **`pud_alloc()` 源码分析**

`pud_alloc()` 是分配页上中间目录 (PUD) 的函数，调用时，它为特定虚拟地址的 PUD 层级分配空间，并返回对应的页表指针。

**源码位置：`arch/x86/mm/pgtable.c`**

```
c复制代码pud_t *pud_alloc(struct mm_struct *mm, pgd_t *pgd, unsigned long addr)
{
    pud_t *pud;

    /* Step 1: 检查 PUD 是否已经存在 */
    if (pgd_none(*pgd)) {
        pud = (pud_t *)get_zeroed_page(GFP_KERNEL);
        if (!pud)
            return NULL;

        pgd_populate(mm, pgd, pud);
    }

    return pud_offset(pgd, addr);
}
```

#### **函数过程分析：**

1. **Step 1: 检查 PUD 是否已存在**：
   - `pgd_none()` 检查 PGD 中是否已经存在与该虚拟地址对应的 PUD。若不存在，系统将分配一个新页面作为 PUD。
2. **Step 2: 分配 PUD 并初始化**：
   - `get_zeroed_page(GFP_KERNEL)` 分配一个新的页面并初始化 PUD。
   - `pgd_populate()` 函数将该新分配的 PUD 填入 PGD 中。
3. **Step 3: 返回对应的 PUD**：
   - `pud_offset()` 函数根据虚拟地址的偏移量返回对应的 PUD。

#### **`pmd_alloc()` 源码分析**

`pmd_alloc()` 是用于分配页中间目录 (PMD) 的函数，它接收一个 PUD 并为其分配一个 PMD。

**源码位置：`arch/x86/mm/pgtable.c`**

```
c复制代码pmd_t *pmd_alloc(struct mm_struct *mm, pud_t *pud, unsigned long addr)
{
    pmd_t *pmd;

    /* Step 1: 检查 PMD 是否存在 */
    if (pud_none(*pud)) {
        pmd = (pmd_t *)get_zeroed_page(GFP_KERNEL);
        if (!pmd)
            return NULL;

        pud_populate(mm, pud, pmd);
    }

    return pmd_offset(pud, addr);
}
```

#### **函数过程分析：**

1. **Step 1: 检查 PMD 是否已存在**：
   - `pud_none()` 检查当前 PUD 项是否为空。若为空，系统将为 PUD 分配新的 PMD 页面。
2. **Step 2: 分配 PMD 并初始化**：
   - `get_zeroed_page(GFP_KERNEL)` 为 PMD 分配一个新页面。
   - `pud_populate()` 函数将新分配的 PMD 填入 PUD 中。
3. **Step 3: 返回对应的 PMD**：
   - `pmd_offset()` 函数根据虚拟地址返回对应的 PMD 项。

#### **`pte_alloc()` 源码分析**

`pte_alloc()` 是分配页表项 (PTE) 的函数，它是完成从虚拟地址到物理地址映射的最后一步。

**源码位置：`arch/x86/mm/pgtable.c`**

```
c复制代码pte_t *pte_alloc(struct mm_struct *mm, pmd_t *pmd, unsigned long addr)
{
    pte_t *pte;

    /* Step 1: 检查 PTE 是否已存在 */
    if (pmd_none(*pmd)) {
        pte = pte_alloc_one(mm);
        if (!pte)
            return NULL;

        pmd_populate(mm, pmd, pte);
    }

    return pte_offset_map(pmd, addr);
}
```

#### **函数过程分析：**

1. **Step 1: 检查 PTE 是否存在**：
   - `pmd_none()` 检查 PMD 中是否已经存在与该虚拟地址对应的 PTE。如果 PTE 尚未分配，系统会为其分配。
2. **Step 2: 分配 PTE**：
   - `pte_alloc_one()` 为 PMD 分配新的 PTE 页面。
   - `pmd_populate()` 函数将新分配的 PTE 填入 PMD 中。
3. **Step 3: 返回对应的 PTE**：
   - `pte_offset_map()` 函数根据虚拟地址的偏移量返回该地址的 PTE。

------

### **4.1.3 设置页表项：`set_pte()`**

在分配完相应的 PTE 后，`set_pte()` 用来设置页表项（PTE），将虚拟地址与实际的物理地址进行映射。

#### **`set_pte()` 源码分析**

**源码位置：`arch/x86/mm/pgtable.c`**

```
c复制代码void set_pte(pte_t *pte, pte_t entry)
{
    *pte = entry;
}
```

#### **函数过程分析：**

1. 更新 PTE

   ：

   - `set_pte()` 简单地将新的 PTE 值写入到页表项中。`entry` 包含了物理地址和页保护标志。
   - 在设置完成后，虚拟地址与物理地址的映射就正式建立了。

------

### **4.1.4 总结**

页表映射是虚拟内存管理的核心，Linux 使用多级页表结构（PGD、PUD、PMD、PTE）来管理虚拟地址和物理地址的映射。页表的分配过程逐级进行，从最高的页全局目录 (PGD) 开始，一直到最低级的页表项 (PTE)，最终完成虚拟地址到物理地址的映射。

- **`pgd_alloc()`**：分配页全局目录。
- **`pud_alloc()`**：分配页上中间目录。
- **`pmd_alloc()`**：分配页中间目录。
- **`pte_alloc()`**：分配页表项，并进行虚拟地址和物理地址的映射。
- **`set_pte()`**：设置页表项，将虚拟地址映射到实际的物理地址。

通过这些函数，内核为进程的每个虚拟地址提供相应的物理内存，从而实现虚拟内存管理和地址空间隔离。



# 第五章